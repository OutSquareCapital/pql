"""DuckDB Relation wrapper using SqlExpr instead of duckdb.Expression.

This file is AUTO-GENERATED by ``scripts/_core_generator.py``
Do not edit manually.
"""

from __future__ import annotations

from typing import TYPE_CHECKING, Any, Literal, Self, SupportsInt, overload

import pyochain as pc
from duckdb import ExplainType, RenderMode

from .._core import DuckHandler, RelHandler, into_duckdb, try_iter

if TYPE_CHECKING:
    from collections.abc import Callable, Iterable

    import numpy as np
    import pandas as pd  # pyright: ignore[reportMissingModuleSource]
    import polars as pl
    import pyarrow as pa
    import tensorflow as tf  # pyright: ignore[reportMissingModuleSource]
    import torch
    from duckdb import sqltypes

    type ParquetFieldIdsType = dict[str, int | ParquetFieldIdsType]


class Relation(RelHandler):
    """Wrapper around DuckDBPyRelation that uses SqlExpr instead of duckdb.Expression.

    This is a composition-based wrapper: it stores a ``_expr: DuckDBPyRelation``
    and delegates all method calls, converting SqlExpr <-> duckdb.Expression
    at the boundary.
    """

    __slots__ = ()

    def __arrow_c_stream__(self, requested_schema: object | None = None) -> Any:
        """Execute and return an ArrowArrayStream through the Arrow PyCapsule Interface.

        https://arrow.apache.org/docs/dev/format/CDataInterface/PyCapsuleInterface.html
        """
        return self.inner().__arrow_c_stream__(requested_schema)

    def __contains__(self, name: str) -> bool:
        return self.inner().__contains__(name)

    def __getattr__(self, name: str) -> Self:
        """Get a projection relation created from this relation, on the provided column name."""
        return self._new(self.inner().__getattr__(name))

    def __getitem__(self, name: str) -> Self:
        """Get a projection relation created from this relation, on the provided column name."""
        return self._new(self.inner().__getitem__(name))

    def __len__(self) -> int:
        """Number of rows in relation."""
        return self.inner().__len__()

    def aggregate(
        self,
        aggr_expr: DuckHandler | str | Iterable[DuckHandler | str],
        group_expr: DuckHandler | str = "",
    ) -> Self:
        """Compute the aggregate aggr_expr by the optional groups group_expr on the relation."""
        return self._new(
            self.inner().aggregate(
                try_iter(aggr_expr).map(into_duckdb),  # pyright: ignore[reportArgumentType]
                into_duckdb(group_expr),
            )
        )

    def any_value(
        self,
        column: str,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Returns the first non-null value from a given column."""
        return self._new(
            self.inner().any_value(column, groups, window_spec, projected_columns)
        )

    def apply(
        self,
        function_name: str,
        function_aggr: str,
        group_expr: str = "",
        function_parameter: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Compute the function of a single column or a list of columns by the optional groups on the relation."""
        return self._new(
            self.inner().apply(
                function_name,
                function_aggr,
                group_expr,
                function_parameter,
                projected_columns,
            )
        )

    def arg_max(
        self,
        arg_column: str,
        value_column: str,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Finds the row with the maximum value for a value column and returns the value of that row for an argument column."""
        return self._new(
            self.inner().arg_max(
                arg_column, value_column, groups, window_spec, projected_columns
            )
        )

    def arg_min(
        self,
        arg_column: str,
        value_column: str,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Finds the row with the minimum value for a value column and returns the value of that row for an argument column."""
        return self._new(
            self.inner().arg_min(
                arg_column, value_column, groups, window_spec, projected_columns
            )
        )

    def arrow(self, batch_size: SupportsInt = 1000000) -> pa.RecordBatchReader:
        """Execute and return an Arrow Record Batch Reader that yields all rows."""
        return self.inner().arrow(batch_size)

    def avg(
        self,
        column: str,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Computes the average on a given column."""
        return self._new(
            self.inner().avg(column, groups, window_spec, projected_columns)
        )

    def bit_and(
        self,
        column: str,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Computes the bitwise AND of all bits present in a given column."""
        return self._new(
            self.inner().bit_and(column, groups, window_spec, projected_columns)
        )

    def bit_or(
        self,
        column: str,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Computes the bitwise OR of all bits present in a given column."""
        return self._new(
            self.inner().bit_or(column, groups, window_spec, projected_columns)
        )

    def bit_xor(
        self,
        column: str,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Computes the bitwise XOR of all bits present in a given column."""
        return self._new(
            self.inner().bit_xor(column, groups, window_spec, projected_columns)
        )

    def bitstring_agg(
        self,
        column: str,
        min: int | None = None,
        max: int | None = None,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Computes a bitstring with bits set for each distinct value in a given column."""
        return self._new(
            self.inner().bitstring_agg(
                column, min, max, groups, window_spec, projected_columns
            )
        )

    def bool_and(
        self,
        column: str,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Computes the logical AND of all values present in a given column."""
        return self._new(
            self.inner().bool_and(column, groups, window_spec, projected_columns)
        )

    def bool_or(
        self,
        column: str,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Computes the logical OR of all values present in a given column."""
        return self._new(
            self.inner().bool_or(column, groups, window_spec, projected_columns)
        )

    def close(self) -> None:
        """Closes the result."""
        return self.inner().close()

    def count(
        self,
        column: str,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Computes the number of elements present in a given column."""
        return self._new(
            self.inner().count(column, groups, window_spec, projected_columns)
        )

    def create(self, table_name: str) -> None:
        """Creates a new table named table_name with the contents of the relation object."""
        return self.inner().create(table_name)

    def create_view(self, view_name: str, replace: bool = True) -> Self:
        """Creates a view named view_name that refers to the relation object."""
        return self._new(self.inner().create_view(view_name, replace))

    def cross(self, other_rel: Self) -> Self:
        """Create cross/cartesian product of two relational objects."""
        return self._new(self.inner().cross(other_rel.inner()))

    def cume_dist(self, window_spec: str, projected_columns: str = "") -> Self:
        """Computes the cumulative distribution within the partition."""
        return self._new(self.inner().cume_dist(window_spec, projected_columns))

    def dense_rank(self, window_spec: str, projected_columns: str = "") -> Self:
        """Computes the dense rank within the partition."""
        return self._new(self.inner().dense_rank(window_spec, projected_columns))

    def describe(self) -> Self:
        """Gives basic statistics (e.g., min, max) and if NULL exists for each column of the relation."""
        return self._new(self.inner().describe())

    def df(self, *, date_as_object: bool = False) -> pd.DataFrame:
        """Execute and fetch all rows as a pandas DataFrame."""
        return self.inner().df(date_as_object=date_as_object)

    def distinct(self) -> Self:
        """Retrieve distinct rows from this relation object."""
        return self._new(self.inner().distinct())

    def except_(self, other_rel: Self) -> Self:
        """Create the set except of this relation object with another relation object in other_rel."""
        return self._new(self.inner().except_(other_rel.inner()))

    def execute(self) -> Self:
        """Transform the relation into a result set."""
        return self._new(self.inner().execute())

    def explain(self, type: ExplainType = ExplainType.STANDARD) -> str:
        return self.inner().explain(type)

    def favg(
        self,
        column: str,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Computes the average of all values present in a given column using a more accurate floating point summation (Kahan Sum)."""
        return self._new(
            self.inner().favg(column, groups, window_spec, projected_columns)
        )

    def fetch_arrow_reader(
        self, batch_size: SupportsInt = 1000000
    ) -> pa.RecordBatchReader:
        """Execute and return an Arrow Record Batch Reader that yields all rows."""
        return self.inner().fetch_arrow_reader(batch_size)

    def fetch_arrow_table(self, batch_size: SupportsInt = 1000000) -> pa.Table:
        """Execute and fetch all rows as an Arrow Table."""
        return self.inner().fetch_arrow_table(batch_size)

    def fetch_df_chunk(
        self, vectors_per_chunk: SupportsInt = 1, *, date_as_object: bool = False
    ) -> pd.DataFrame:
        """Execute and fetch a chunk of the rows."""
        return self.inner().fetch_df_chunk(
            vectors_per_chunk, date_as_object=date_as_object
        )

    def fetch_record_batch(
        self, rows_per_batch: SupportsInt = 1000000
    ) -> pa.RecordBatchReader:
        """Execute and return an Arrow Record Batch Reader that yields all rows."""
        return self.inner().fetch_record_batch(rows_per_batch)

    def fetchall(self) -> pc.Vec[tuple[Any, ...]]:
        """Execute and fetch all rows as a list of tuples."""
        return pc.Vec.from_ref(self.inner().fetchall())

    def fetchdf(self, *, date_as_object: bool = False) -> pd.DataFrame:
        """Execute and fetch all rows as a pandas DataFrame."""
        return self.inner().fetchdf(date_as_object=date_as_object)

    def fetchmany(self, size: SupportsInt = 1) -> pc.Vec[tuple[Any, ...]]:
        """Execute and fetch the next set of rows as a list of tuples."""
        return pc.Vec.from_ref(self.inner().fetchmany(size))

    def fetchnumpy(self) -> pc.Dict[str, np.typing.NDArray[Any] | pd.Categorical]:
        """Execute and fetch all rows as a Python dict mapping each column to one numpy arrays."""
        return pc.Dict.from_ref(self.inner().fetchnumpy())

    def fetchone(self) -> tuple[Any, ...] | None:
        """Execute and fetch a single row as a tuple."""
        return self.inner().fetchone()

    def filter(self, filter_expr: DuckHandler | str) -> Self:
        """Filter the relation object by the filter in filter_expr."""
        return self._new(self.inner().filter(into_duckdb(filter_expr)))

    def first(self, column: str, groups: str = "", projected_columns: str = "") -> Self:
        """Returns the first value of a given column."""
        return self._new(self.inner().first(column, groups, projected_columns))

    def first_value(
        self, column: str, window_spec: str = "", projected_columns: str = ""
    ) -> Self:
        """Computes the first value within the group or partition."""
        return self._new(
            self.inner().first_value(column, window_spec, projected_columns)
        )

    def fsum(
        self,
        column: str,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Computes the sum of all values present in a given column using a more accurate floating point summation (Kahan Sum)."""
        return self._new(
            self.inner().fsum(column, groups, window_spec, projected_columns)
        )

    def geomean(
        self, column: str, groups: str = "", projected_columns: str = ""
    ) -> Self:
        """Computes the geometric mean over all values present in a given column."""
        return self._new(self.inner().geomean(column, groups, projected_columns))

    def histogram(
        self,
        column: str,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Computes the histogram over all values present in a given column."""
        return self._new(
            self.inner().histogram(column, groups, window_spec, projected_columns)
        )

    def insert(self, values: list[object]) -> None:
        """Inserts the given values into the relation."""
        return self.inner().insert(values)

    def insert_into(self, table_name: str) -> None:
        """Inserts the relation object into an existing table named table_name."""
        return self.inner().insert_into(table_name)

    def intersect(self, other_rel: Self) -> Self:
        """Create the set intersection of this relation object with another relation object in other_rel."""
        return self._new(self.inner().intersect(other_rel.inner()))

    def join(
        self, other_rel: Self, condition: DuckHandler | str, how: str = "inner"
    ) -> Self:
        """Join the relation object with another relation object in other_rel using the join condition expression in join_condition. Types supported are 'inner', 'left', 'right', 'outer', 'semi' and 'anti'."""
        return self._new(
            self.inner().join(other_rel.inner(), into_duckdb(condition), how)
        )

    def lag(
        self,
        column: str,
        window_spec: str,
        offset: SupportsInt = 1,
        default_value: str = "NULL",
        ignore_nulls: bool = False,
        projected_columns: str = "",
    ) -> Self:
        """Computes the lag within the partition."""
        return self._new(
            self.inner().lag(
                column,
                window_spec,
                offset,
                default_value,
                ignore_nulls,
                projected_columns,
            )
        )

    def last(self, column: str, groups: str = "", projected_columns: str = "") -> Self:
        """Returns the last value of a given column."""
        return self._new(self.inner().last(column, groups, projected_columns))

    def last_value(
        self, column: str, window_spec: str = "", projected_columns: str = ""
    ) -> Self:
        """Computes the last value within the group or partition."""
        return self._new(
            self.inner().last_value(column, window_spec, projected_columns)
        )

    def lead(
        self,
        column: str,
        window_spec: str,
        offset: SupportsInt = 1,
        default_value: str = "NULL",
        ignore_nulls: bool = False,
        projected_columns: str = "",
    ) -> Self:
        """Computes the lead within the partition."""
        return self._new(
            self.inner().lead(
                column,
                window_spec,
                offset,
                default_value,
                ignore_nulls,
                projected_columns,
            )
        )

    def limit(self, n: SupportsInt, offset: SupportsInt = 0) -> Self:
        """Only retrieve the first n rows from this relation object, starting at offset."""
        return self._new(self.inner().limit(n, offset))

    def list(
        self,
        column: str,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Returns a list containing all values present in a given column."""
        return self._new(
            self.inner().list(column, groups, window_spec, projected_columns)
        )

    def map(
        self,
        map_function: Callable[..., Any],
        *,
        schema: dict[str, sqltypes.DuckDBPyType] | None = None,
    ) -> Self:
        """Calls the passed function on the relation."""
        return self._new(self.inner().map(map_function, schema=schema))

    def max(
        self,
        column: str,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Returns the maximum value present in a given column."""
        return self._new(
            self.inner().max(column, groups, window_spec, projected_columns)
        )

    def mean(
        self,
        column: str,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Computes the average on a given column."""
        return self._new(
            self.inner().mean(column, groups, window_spec, projected_columns)
        )

    def median(
        self,
        column: str,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Computes the median over all values present in a given column."""
        return self._new(
            self.inner().median(column, groups, window_spec, projected_columns)
        )

    def min(
        self,
        column: str,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Returns the minimum value present in a given column."""
        return self._new(
            self.inner().min(column, groups, window_spec, projected_columns)
        )

    def mode(
        self,
        column: str,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Computes the mode over all values present in a given column."""
        return self._new(
            self.inner().mode(column, groups, window_spec, projected_columns)
        )

    def n_tile(
        self, window_spec: str, num_buckets: SupportsInt, projected_columns: str = ""
    ) -> Self:
        """Divides the partition as equally as possible into num_buckets."""
        return self._new(
            self.inner().n_tile(window_spec, num_buckets, projected_columns)
        )

    def nth_value(
        self,
        column: str,
        window_spec: str,
        offset: SupportsInt,
        ignore_nulls: bool = False,
        projected_columns: str = "",
    ) -> Self:
        """Computes the nth value within the partition."""
        return self._new(
            self.inner().nth_value(
                column, window_spec, offset, ignore_nulls, projected_columns
            )
        )

    def order(self, order_expr: str) -> Self:
        """Reorder the relation object by order_expr."""
        return self._new(self.inner().order(order_expr))

    def percent_rank(self, window_spec: str, projected_columns: str = "") -> Self:
        """Computes the relative rank within the partition."""
        return self._new(self.inner().percent_rank(window_spec, projected_columns))

    @overload
    def pl(
        self, batch_size: SupportsInt = 1000000, *, lazy: Literal[False] = ...
    ) -> pl.DataFrame: ...

    @overload
    def pl(
        self, batch_size: SupportsInt = 1000000, *, lazy: Literal[True]
    ) -> pl.LazyFrame: ...

    def pl(
        self, batch_size: SupportsInt = 1000000, *, lazy: bool = False
    ) -> pl.DataFrame | pl.LazyFrame:
        """Execute and fetch all rows as a Polars DataFrame."""
        return self.inner().pl(batch_size, lazy=lazy)

    def product(
        self,
        column: str,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Returns the product of all values present in a given column."""
        return self._new(
            self.inner().product(column, groups, window_spec, projected_columns)
        )

    def project(self, *args: str | DuckHandler, groups: str = "") -> Self:
        """Project the relation object by the projection in project_expr."""
        return self._new(
            self.inner().project(*pc.Iter(args).map(into_duckdb), groups=groups)
        )

    def quantile(
        self,
        column: str,
        q: float | list[float] = 0.5,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Computes the exact quantile value for a given column."""
        return self._new(
            self.inner().quantile(column, q, groups, window_spec, projected_columns)
        )

    def quantile_cont(
        self,
        column: str,
        q: float | list[float] = 0.5,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Computes the interpolated quantile value for a given column."""
        return self._new(
            self.inner().quantile_cont(
                column, q, groups, window_spec, projected_columns
            )
        )

    def quantile_disc(
        self,
        column: str,
        q: float | list[float] = 0.5,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Computes the exact quantile value for a given column."""
        return self._new(
            self.inner().quantile_disc(
                column, q, groups, window_spec, projected_columns
            )
        )

    def query(self, virtual_table_name: str, sql_query: str) -> Self:
        """Run the given SQL query in sql_query on the view named virtual_table_name that refers to the relation object."""
        return self._new(self.inner().query(virtual_table_name, sql_query))

    def rank(self, window_spec: str, projected_columns: str = "") -> Self:
        """Computes the rank within the partition."""
        return self._new(self.inner().rank(window_spec, projected_columns))

    def rank_dense(self, window_spec: str, projected_columns: str = "") -> Self:
        """Computes the dense rank within the partition."""
        return self._new(self.inner().rank_dense(window_spec, projected_columns))

    def record_batch(self, batch_size: SupportsInt = 1000000) -> pa.RecordBatchReader:
        return self.inner().record_batch(batch_size)

    def row_number(self, window_spec: str, projected_columns: str = "") -> Self:
        """Computes the row number within the partition."""
        return self._new(self.inner().row_number(window_spec, projected_columns))

    def select(self, *args: str | DuckHandler, groups: str = "") -> Self:
        """Project the relation object by the projection in project_expr."""
        return self._new(
            self.inner().select(*pc.Iter(args).map(into_duckdb), groups=groups)
        )

    def select_dtypes(self, types: list[sqltypes.DuckDBPyType | str]) -> Self:
        """Select columns from the relation, by filtering based on type(s)."""
        return self._new(self.inner().select_dtypes(types))

    def select_types(self, types: list[sqltypes.DuckDBPyType | str]) -> Self:
        """Select columns from the relation, by filtering based on type(s)."""
        return self._new(self.inner().select_types(types))

    def set_alias(self, alias: str) -> Self:
        """Rename the relation object to new alias."""
        return self._new(self.inner().set_alias(alias))

    def show(
        self,
        *,
        max_width: SupportsInt | None = None,
        max_rows: SupportsInt | None = None,
        max_col_width: SupportsInt | None = None,
        null_value: str | None = None,
        render_mode: RenderMode | None = None,
    ) -> None:
        """Display a summary of the data."""
        return self.inner().show(
            max_width=max_width,
            max_rows=max_rows,
            max_col_width=max_col_width,
            null_value=null_value,
            render_mode=render_mode,
        )

    def sort(self, *args: DuckHandler) -> Self:
        """Reorder the relation object by the provided expressions."""
        return self._new(self.inner().sort(*pc.Iter(args).map(lambda arg: arg.inner())))

    def sql_query(self) -> str:
        """Get the SQL query that is equivalent to the relation."""
        return self.inner().sql_query()

    def std(
        self,
        column: str,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Computes the sample standard deviation for a given column."""
        return self._new(
            self.inner().std(column, groups, window_spec, projected_columns)
        )

    def stddev(
        self,
        column: str,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Computes the sample standard deviation for a given column."""
        return self._new(
            self.inner().stddev(column, groups, window_spec, projected_columns)
        )

    def stddev_pop(
        self,
        column: str,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Computes the population standard deviation for a given column."""
        return self._new(
            self.inner().stddev_pop(column, groups, window_spec, projected_columns)
        )

    def stddev_samp(
        self,
        column: str,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Computes the sample standard deviation for a given column."""
        return self._new(
            self.inner().stddev_samp(column, groups, window_spec, projected_columns)
        )

    def string_agg(
        self,
        column: str,
        sep: str = ",",
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Concatenates the values present in a given column with a separator."""
        return self._new(
            self.inner().string_agg(column, sep, groups, window_spec, projected_columns)
        )

    def sum(
        self,
        column: str,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Computes the sum of all values present in a given column."""
        return self._new(
            self.inner().sum(column, groups, window_spec, projected_columns)
        )

    def tf(self) -> pc.Dict[str, tf.Tensor]:
        """Fetch a result as dict of TensorFlow Tensors."""
        return pc.Dict.from_ref(self.inner().tf())

    def to_arrow_table(self, batch_size: SupportsInt = 1000000) -> pa.Table:
        """Execute and fetch all rows as an Arrow Table."""
        return self.inner().to_arrow_table(batch_size)

    def to_csv(
        self,
        file_name: str,
        *,
        sep: str | None = None,
        na_rep: str | None = None,
        header: bool | None = None,
        quotechar: str | None = None,
        escapechar: str | None = None,
        date_format: str | None = None,
        timestamp_format: str | None = None,
        quoting: str | int | None = None,
        encoding: str | None = None,
        compression: str | None = None,
        overwrite: bool | None = None,
        per_thread_output: bool | None = None,
        use_tmp_file: bool | None = None,
        partition_by: list[str] | None = None,
        write_partition_columns: bool | None = None,
    ) -> None:
        """Write the relation object to a CSV file in 'file_name'."""
        return self.inner().to_csv(
            file_name,
            sep=sep,
            na_rep=na_rep,
            header=header,
            quotechar=quotechar,
            escapechar=escapechar,
            date_format=date_format,
            timestamp_format=timestamp_format,
            quoting=quoting,
            encoding=encoding,
            compression=compression,
            overwrite=overwrite,
            per_thread_output=per_thread_output,
            use_tmp_file=use_tmp_file,
            partition_by=partition_by,
            write_partition_columns=write_partition_columns,
        )

    def to_df(self, *, date_as_object: bool = False) -> pd.DataFrame:
        """Execute and fetch all rows as a pandas DataFrame."""
        return self.inner().to_df(date_as_object=date_as_object)

    def to_parquet(
        self,
        file_name: str,
        *,
        compression: str | None = None,
        field_ids: ParquetFieldIdsType | Literal["auto"] | None = None,
        row_group_size_bytes: int | str | None = None,
        row_group_size: int | None = None,
        overwrite: bool | None = None,
        per_thread_output: bool | None = None,
        use_tmp_file: bool | None = None,
        partition_by: list[str] | None = None,
        write_partition_columns: bool | None = None,
        append: bool | None = None,
        filename_pattern: str | None = None,
        file_size_bytes: str | int | None = None,
    ) -> None:
        """Write the relation object to a Parquet file in 'file_name'."""
        return self.inner().to_parquet(
            file_name,
            compression=compression,
            field_ids=field_ids,
            row_group_size_bytes=row_group_size_bytes,
            row_group_size=row_group_size,
            overwrite=overwrite,
            per_thread_output=per_thread_output,
            use_tmp_file=use_tmp_file,
            partition_by=partition_by,
            write_partition_columns=write_partition_columns,
            append=append,
            filename_pattern=filename_pattern,
            file_size_bytes=file_size_bytes,
        )

    def to_table(self, table_name: str) -> None:
        """Creates a new table named table_name with the contents of the relation object."""
        return self.inner().to_table(table_name)

    def to_view(self, view_name: str, replace: bool = True) -> Self:
        """Creates a view named view_name that refers to the relation object."""
        return self._new(self.inner().to_view(view_name, replace))

    def torch(self) -> pc.Dict[str, torch.Tensor]:
        """Fetch a result as dict of PyTorch Tensors."""
        return pc.Dict.from_ref(self.inner().torch())

    def union(self, union_rel: Self) -> Self:
        """Create the set union of this relation object with another relation object in other_rel."""
        return self._new(self.inner().union(union_rel.inner()))

    def unique(self, unique_aggr: str) -> Self:
        """Returns the distinct values in a column."""
        return self._new(self.inner().unique(unique_aggr))

    def update(
        self, set: DuckHandler | str, *, condition: DuckHandler | str | None = None
    ) -> None:
        """Update the given relation with the provided expressions."""
        return self.inner().update(into_duckdb(set), condition=into_duckdb(condition))

    def value_counts(self, column: str, groups: str = "") -> Self:
        """Computes the number of elements present in a given column, also projecting the original column."""
        return self._new(self.inner().value_counts(column, groups))

    def var(
        self,
        column: str,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Computes the sample variance for a given column."""
        return self._new(
            self.inner().var(column, groups, window_spec, projected_columns)
        )

    def var_pop(
        self,
        column: str,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Computes the population variance for a given column."""
        return self._new(
            self.inner().var_pop(column, groups, window_spec, projected_columns)
        )

    def var_samp(
        self,
        column: str,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Computes the sample variance for a given column."""
        return self._new(
            self.inner().var_samp(column, groups, window_spec, projected_columns)
        )

    def variance(
        self,
        column: str,
        groups: str = "",
        window_spec: str = "",
        projected_columns: str = "",
    ) -> Self:
        """Computes the sample variance for a given column."""
        return self._new(
            self.inner().variance(column, groups, window_spec, projected_columns)
        )

    def write_csv(
        self,
        file_name: str,
        *,
        sep: str | None = None,
        na_rep: str | None = None,
        header: bool | None = None,
        quotechar: str | None = None,
        escapechar: str | None = None,
        date_format: str | None = None,
        timestamp_format: str | None = None,
        quoting: str | int | None = None,
        encoding: str | None = None,
        compression: str | None = None,
        overwrite: bool | None = None,
        per_thread_output: bool | None = None,
        use_tmp_file: bool | None = None,
        partition_by: list[str] | None = None,
        write_partition_columns: bool | None = None,
    ) -> None:
        """Write the relation object to a CSV file in 'file_name'."""
        return self.inner().write_csv(
            file_name,
            sep=sep,
            na_rep=na_rep,
            header=header,
            quotechar=quotechar,
            escapechar=escapechar,
            date_format=date_format,
            timestamp_format=timestamp_format,
            quoting=quoting,
            encoding=encoding,
            compression=compression,
            overwrite=overwrite,
            per_thread_output=per_thread_output,
            use_tmp_file=use_tmp_file,
            partition_by=partition_by,
            write_partition_columns=write_partition_columns,
        )

    def write_parquet(
        self,
        file_name: str,
        *,
        compression: str | None = None,
        field_ids: ParquetFieldIdsType | Literal["auto"] | None = None,
        row_group_size_bytes: str | int | None = None,
        row_group_size: int | None = None,
        overwrite: bool | None = None,
        per_thread_output: bool | None = None,
        use_tmp_file: bool | None = None,
        partition_by: list[str] | None = None,
        write_partition_columns: bool | None = None,
        append: bool | None = None,
        filename_pattern: str | None = None,
        file_size_bytes: str | int | None = None,
    ) -> None:
        """Write the relation object to a Parquet file in 'file_name'."""
        return self.inner().write_parquet(
            file_name,
            compression=compression,
            field_ids=field_ids,
            row_group_size_bytes=row_group_size_bytes,
            row_group_size=row_group_size,
            overwrite=overwrite,
            per_thread_output=per_thread_output,
            use_tmp_file=use_tmp_file,
            partition_by=partition_by,
            write_partition_columns=write_partition_columns,
            append=append,
            filename_pattern=filename_pattern,
            file_size_bytes=file_size_bytes,
        )

    @property
    def alias(self) -> str:
        """Get the name of the current alias."""
        return self.inner().alias

    @property
    def columns(self) -> pc.Vec[str]:
        """Return a list containing the names of the columns of the relation."""
        return pc.Vec.from_ref(self.inner().columns)

    @property
    def description(
        self,
    ) -> pc.Vec[tuple[str, sqltypes.DuckDBPyType, None, None, None, None, None]]:
        """Return the description of the result."""
        return pc.Vec.from_ref(self.inner().description)

    @property
    def dtypes(self) -> pc.Vec[sqltypes.DuckDBPyType]:
        """Return a list containing the types of the columns of the relation."""
        return pc.Vec.from_ref(self.inner().dtypes)  # pyright: ignore[reportReturnType]

    @property
    def shape(self) -> tuple[int, int]:
        """Tuple of # of rows, # of columns in relation."""
        return self.inner().shape

    @property
    def type(self) -> str:
        """Get the type of the relation."""
        return self.inner().type

    @property
    def types(self) -> pc.Vec[sqltypes.DuckDBPyType]:
        """Return a list containing the types of the columns of the relation."""
        return pc.Vec.from_ref(self.inner().types)


class Expression(DuckHandler):
    """Wrapper around Expression that uses SqlExpr instead of duckdb.Expression.

    This is a composition-based wrapper: it stores a ``_expr: Expression``
    and delegates all method calls, converting SqlExpr <-> duckdb.Expression
    at the boundary.
    """

    __slots__ = ()

    def __add__(self, other: Self) -> Self:
        """Add expr to self.

        Parameters:
                expr: The expression to add together with

        Returns:
                FunctionExpression: self '+' expr
        """
        return self._new(self.inner().__add__(other.inner()))

    def __and__(self, other: Self) -> Self:
        """Binary-and self together with expr.

        Parameters:
                expr: The expression to AND together with self

        Returns:
                FunctionExpression: self '&' expr
        """
        return self._new(self.inner().__and__(other.inner()))

    def __div__(self, other: Self) -> Self:
        """Divide self by expr.

        Parameters:
                expr: The expression to divide by

        Returns:
                FunctionExpression: self '/' expr
        """
        return self._new(self.inner().__div__(other.inner()))

    def __eq__(self, other: Self) -> Self:  # pyright: ignore[reportIncompatibleMethodOverride]
        """Create an equality expression between two expressions.

        Parameters:
                expr: The expression to check equality with

        Returns:
                FunctionExpression: self '=' expr
        """
        return self._new(self.inner().__eq__(other.inner()))

    def __floordiv__(self, other: Self) -> Self:
        """(Floor) Divide self by expr.

        Parameters:
                expr: The expression to (floor) divide by

        Returns:
                FunctionExpression: self '//' expr
        """
        return self._new(self.inner().__floordiv__(other.inner()))

    def __ge__(self, other: Self) -> Self:
        """Create a greater than or equal expression between two expressions.

        Parameters:
                expr: The expression to check

        Returns:
                FunctionExpression: self '>=' expr
        """
        return self._new(self.inner().__ge__(other.inner()))

    def __gt__(self, other: Self) -> Self:
        """Create a greater than expression between two expressions.

        Parameters:
                expr: The expression to check

        Returns:
                FunctionExpression: self '>' expr
        """
        return self._new(self.inner().__gt__(other.inner()))

    def __invert__(self) -> Self:
        """Create a binary-not expression from self.

        Returns:
                FunctionExpression: ~self
        """
        return self._new(self.inner().__invert__())

    def __le__(self, other: Self) -> Self:
        """Create a less than or equal expression between two expressions.

        Parameters:
                expr: The expression to check

        Returns:
                FunctionExpression: self '<=' expr
        """
        return self._new(self.inner().__le__(other.inner()))

    def __lt__(self, other: Self) -> Self:
        """Create a less than expression between two expressions.

        Parameters:
                expr: The expression to check

        Returns:
                FunctionExpression: self '<' expr
        """
        return self._new(self.inner().__lt__(other.inner()))

    def __mod__(self, other: Self) -> Self:
        """Modulo self by expr.

        Parameters:
                expr: The expression to modulo by

        Returns:
                FunctionExpression: self '%' expr
        """
        return self._new(self.inner().__mod__(other.inner()))

    def __mul__(self, other: Self) -> Self:
        """Multiply self by expr.

        Parameters:
                expr: The expression to multiply by

        Returns:
                FunctionExpression: self '*' expr
        """
        return self._new(self.inner().__mul__(other.inner()))

    def __ne__(self, other: Self) -> Self:  # pyright: ignore[reportIncompatibleMethodOverride]
        """Create an inequality expression between two expressions.

        Parameters:
                expr: The expression to check inequality with

        Returns:
                FunctionExpression: self '!=' expr
        """
        return self._new(self.inner().__ne__(other.inner()))

    def __neg__(self) -> Self:
        """Negate the expression.

        Returns:
                FunctionExpression: -self
        """
        return self._new(self.inner().__neg__())

    def __or__(self, other: Self) -> Self:
        """Binary-or self together with expr.

        Parameters:
                expr: The expression to OR together with self

        Returns:
                FunctionExpression: self '|' expr
        """
        return self._new(self.inner().__or__(other.inner()))

    def __pow__(self, other: Self) -> Self:
        """Power self by expr.

        Parameters:
                expr: The expression to power by

        Returns:
                FunctionExpression: self '**' expr
        """
        return self._new(self.inner().__pow__(other.inner()))

    def __radd__(self, other: Self) -> Self:
        """Add expr to self.

        Parameters:
                expr: The expression to add together with

        Returns:
                FunctionExpression: self '+' expr
        """
        return self._new(self.inner().__radd__(other.inner()))

    def __rand__(self, other: Self) -> Self:
        """Binary-and self together with expr.

        Parameters:
                expr: The expression to AND together with self

        Returns:
                FunctionExpression: expr '&' self
        """
        return self._new(self.inner().__rand__(other.inner()))

    def __rdiv__(self, other: Self) -> Self:
        """Divide self by expr.

        Parameters:
                expr: The expression to divide by

        Returns:
                FunctionExpression: self '/' expr
        """
        return self._new(self.inner().__rdiv__(other.inner()))

    def __rfloordiv__(self, other: Self) -> Self:
        """(Floor) Divide self by expr.

        Parameters:
                expr: The expression to (floor) divide by

        Returns:
                FunctionExpression: self '//' expr
        """
        return self._new(self.inner().__rfloordiv__(other.inner()))

    def __rmod__(self, other: Self) -> Self:
        """Modulo self by expr.

        Parameters:
                expr: The expression to modulo by

        Returns:
                FunctionExpression: self '%' expr
        """
        return self._new(self.inner().__rmod__(other.inner()))

    def __rmul__(self, other: Self) -> Self:
        """Multiply self by expr.

        Parameters:
                expr: The expression to multiply by

        Returns:
                FunctionExpression: self '*' expr
        """
        return self._new(self.inner().__rmul__(other.inner()))

    def __ror__(self, other: Self) -> Self:
        """Binary-or self together with expr.

        Parameters:
                expr: The expression to OR together with self

        Returns:
                FunctionExpression: expr '|' self
        """
        return self._new(self.inner().__ror__(other.inner()))

    def __rpow__(self, other: Self) -> Self:
        """Power self by expr.

        Parameters:
                expr: The expression to power by

        Returns:
                FunctionExpression: self '**' expr
        """
        return self._new(self.inner().__rpow__(other.inner()))

    def __rsub__(self, other: Self) -> Self:
        """Subtract expr from self.

        Parameters:
                expr: The expression to subtract from

        Returns:
                FunctionExpression: self '-' expr
        """
        return self._new(self.inner().__rsub__(other.inner()))

    def __rtruediv__(self, other: Self) -> Self:
        """Divide self by expr.

        Parameters:
                expr: The expression to divide by

        Returns:
                FunctionExpression: self '/' expr
        """
        return self._new(self.inner().__rtruediv__(other.inner()))

    def __sub__(self, other: Self) -> Self:
        """Subtract expr from self.

        Parameters:
                expr: The expression to subtract from

        Returns:
                FunctionExpression: self '-' expr
        """
        return self._new(self.inner().__sub__(other.inner()))

    def __truediv__(self, other: Self) -> Self:
        """Divide self by expr.

        Parameters:
                expr: The expression to divide by

        Returns:
                FunctionExpression: self '/' expr
        """
        return self._new(self.inner().__truediv__(other.inner()))

    def alias(self, name: str) -> Self:
        """Create a copy of this expression with the given alias.

        Parameters:
                name: The alias to use for the expression, this will affect how it can be referenced.

        Returns:
                Expression: self with an alias.
        """
        return self._new(self.inner().alias(name))

    def asc(self) -> Self:
        """Set the order by modifier to ASCENDING."""
        return self._new(self.inner().asc())

    def between(self, lower: Self, upper: Self) -> Self:
        return self._new(self.inner().between(lower.inner(), upper.inner()))

    def cast(self, type: sqltypes.DuckDBPyType) -> Self:
        """Create a CastExpression to type from self.

        Parameters:
                type: The type to cast to

        Returns:
                CastExpression: self::type
        """
        return self._new(self.inner().cast(type))

    def collate(self, collation: str) -> Self:
        return self._new(self.inner().collate(collation))

    def desc(self) -> Self:
        """Set the order by modifier to DESCENDING."""
        return self._new(self.inner().desc())

    def get_name(self) -> str:
        """Return the stringified version of the expression.

        Returns:
                str: The string representation.
        """
        return self.inner().get_name()

    def is_in(self, *args: Self) -> Self:
        """Return an IN expression comparing self to the input arguments.

        Returns:
                DuckDBPyExpression: The compare IN expression
        """
        return self._new(self.inner().isin(*pc.Iter(args).map(lambda arg: arg.inner())))

    def is_not_in(self, *args: Self) -> Self:
        """Return a NOT IN expression comparing self to the input arguments.

        Returns:
                DuckDBPyExpression: The compare NOT IN expression
        """
        return self._new(
            self.inner().isnotin(*pc.Iter(args).map(lambda arg: arg.inner()))
        )

    def is_not_null(self) -> Self:
        """Create a binary IS NOT NULL expression from self.

        Returns:
                DuckDBPyExpression: self IS NOT NULL
        """
        return self._new(self.inner().isnotnull())

    def is_null(self) -> Self:
        """Create a binary IS NULL expression from self.

        Returns:
                DuckDBPyExpression: self IS NULL
        """
        return self._new(self.inner().isnull())

    def nulls_first(self) -> Self:
        """Set the NULL order by modifier to NULLS FIRST."""
        return self._new(self.inner().nulls_first())

    def nulls_last(self) -> Self:
        """Set the NULL order by modifier to NULLS LAST."""
        return self._new(self.inner().nulls_last())

    def otherwise(self, value: Self) -> Self:
        """Add an ELSE <value> clause to the CaseExpression.

        Parameters:
                value: The value to use if none of the WHEN conditions are met.

        Returns:
                CaseExpression: self with an ELSE clause.
        """
        return self._new(self.inner().otherwise(value.inner()))

    def show(self) -> None:
        """Print the stringified version of the expression."""
        return self.inner().show()

    def when(self, condition: Self, value: Self) -> Self:
        """Add an additional WHEN <condition> THEN <value> clause to the CaseExpression.

        Parameters:
                condition: The condition that must be met.
                value: The value to use if the condition is met.

        Returns:
                CaseExpression: self with an additional WHEN clause.
        """
        return self._new(self.inner().when(condition.inner(), value.inner()))
